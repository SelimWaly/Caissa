# Caissa Chess Engine

[![LinuxBuildStatus](https://github.com/Witek902/Caissa/workflows/Linux/badge.svg)](https://github.com/Witek902/Caissa/actions/workflows/linux.yml)

![ArtImage](https://user-images.githubusercontent.com/5882734/193368109-abce432b-85e9-4f11-bb3c-57fd3d27db22.jpg?raw=true)
<p style='text-align: right;'><em>(image generated with DALLÂ·E 2)</em></p>

## Overview

Strong, UCI command-line chess engine written in C++ from scratch in development since early 2021.

### Playing strength

* CCRL 40/2 FRC Score: **3695** (#7) (version 1.7)
* CCRL 40/15 4CPU Score: **3417** (#17) (version 1.7)
* CCRL 2+1 8CPU Score: **3582** (#18) (version 1.7)
* CEGT 40/4 Score: **3356** (#24) (version 1.6)
* CEGT 40/20 Score: **3372** (#24) (version 1.7)
* SPCC Score: **3518** (#21) (version 1.7)
* Ipman Chess Score: **3360** (#28) (version 1.7)

## History / Originality

The engine is written completely from scratch. In early versions it was using simple PeSTO evaluation, then replaced with Stockfish NNUE for a short period of time. Since version 0.7, Caissa uses it's own efficiently-updated neural network trained with Caissa self-play games using custom trainer. Thus, in some sense the first own Caissa net is based on Stockfish's net, however it was much weaker because of small data set used back then (few million positions). Currently (as of version 1.7) there were over 750M newly generated positions used. Also, the old selfplay games are successively purged so that the newer nets are trained only on most recent games generated by most recent net, and so on.

Runtime neural network evaluation code is placed in [PackedNeuralNetwork.cpp](https://github.com/Witek902/Caissa/blob/devel/src/backend/PackedNeuralNetwork.cpp) and was inspired by [nnue.md document](https://github.com/glinscott/nnue-pytorch/blob/master/docs/nnue.md). The neural network trainer is written completely from scratch and is located in [NetworkTrainer.cpp](https://github.com/Witek902/Caissa/blob/devel/src/utils/NetworkTrainer.cpp), [NeuralNetwork.cpp](https://github.com/Witek902/Caissa/blob/devel/src/utils/NeuralNetwork.cpp) and other NeuralNetwork* files. The trainer is purely CPU-based and is heavily optimized to utilize many threads and AVX instructions as well as it exploits sparse nature of the nets.

The games are generated with [SelfPlay.cpp](https://github.com/Witek902/Caissa/blob/devel/src/utils/SelfPlay.cpp) utility that generates games at fixed node count / depth and dumps them to custom binary game format to save space. The opening books used are either Stefan's Pohl [UHO books](https://www.sp-cc.de/uho_2022.htm) or DFRC (Double Fischer Random Chess) openings with few random moves played at the beginning.

### Supported UCI options

* **Hash** (int) Sets transposition table size in megabytes.
* **MultiPV** (int) Specifies number of searched and printed PV lines.
* **MoveOverhead** (int) Sets move overhead in milliseconds. Should be increased if the engine is loosing on time.
* **Threads** (int) Sets number of threads used for searching.
* **Ponder** (bool) Enables pondering.
* **EvalFile** (string) Neural network evaluation file.
* **SyzygyPath** (string) Semicolon-separated list of paths to Syzygy endgame tablebases.
* **SyzygyProbeLimit** (int) Maximum number of piece on the board where Syzygy tablebases can be used.
* **GaviotaTbPath** (string) Path to Gaviota endgame tablebases.
* **GaviotaTbCache** (int) Gaviota cache size in megabytes.
* **UCI_AnalyseMode** (bool) Enables analysis mode: search full PV lines and disable any depth constrains.
* **UseSAN** (bool) Enables short algebraic notation output (FIDE standard) instead of default long algebraic notation.
* **ColorConsoleOutput** (bool) Enables colorful console output for better readability.


### Provided EXE versions

* **AVX2/BMI2** Fastest, requires a x64 CPU with AVX2 and BMI2 instruction set support.
* **POPCNT** Slower, requires a x64 CPU with SSE4 and POPCNT instruction set support.
* **Legacy** Slowest, requires any x64 CPU.


## Features

#### General
* UCI protocol
* Neural network evaluation
* Syzygy and Gaviota endgame tablebases support
* Chess960 (Fischer Random) support

#### Search Algorithm
* Negamax with alpha-beta pruning
* Iterative Deepening with Aspiration Windows
* Principal Variation Search (PVS)
* Zero Window Search
* Quiescence Search
* Transposition Table
* Multi-PV search
* Multithreaded search via shared transposition table

#### Evaluation
* Neural network evaluation
  * 704&rarr;1280&rarr;1 architecture
  * effectively updated first layer, AVX2/SSE2 accelerated
  * clipped-ReLU activation function
  * 8 variants (aka. buckets) of last layer weights selected based on piece count
  * input features: absolute piece coordinates with horizontal symmetry, no king-relative features
* Simple evaluation function based purely on king-relative piece square tables (PSQT)
* Blending between neural net eval and simple eval based on PSQT value
* Special endgame evaluation routines

#### Neural net trainer
* Custom CPU-based trainer using Adam algorithm
* Heavily optmizized using AVX intstructions, multithreading and exploiting sparsity of first layer input
* NN and PSQT trained on data generated during self-play matches (mixture of regular chess, FRC and DFRC games, over 1 billion positions in total)

#### Selectivity
* Null Move Reductions
* Late Move Reductions & Pruning
* Futility Pruning
* Mate Distance Pruning
* Singular Move Extensions
* Upcoming repetition detection

#### Move Ordering
* Most Valuable Victim + capture history
* Winning/Losing Captures (Static Exchange Evaluation)
* Killer/History/Counter/Followup Move Heuristic
* Sacrifice penalty / threat bonus
* Custom ordering for nodes near the root based on time spent on move

#### Time Management
* Heuristics based on approximate move count left and score fluctuations.
* Reducing search time for singular root moves

#### Misc
* Large Pages Support for Transposition Table
* Magic Bitboards
* Handling non-standard chess positions (e.g. 64 pieces on the board, etc.)
* Outstanding performance at ultra-short games (sub-second for whole game).

## Modules

The projects comprises following modules:
  * _backend_ (library) - engine's core
  * _frontend_ (executable) - UCI wrapper for the backend
  * _utils_ (executable) - various utilities, such as unit tests, neural network trainer, self-play data generator, etc.


## Compilation

### Linux

To compile for Linux use CMake:
```
mkdir build; cd build
cmake -DCMAKE_BUILD_TYPE=Release ..
make
```

**NOTE:** Currently, by default project compiles with AVX2/BMI2 support. If your CPU does not support these instructions you need to modify main CMakeLists.txt file manually.

There are three configurations supported:
* **Release** - final version, without asserts, etc.
* **RelWithDebInfo** - development version with asserts enabled and with optimizations enabled for better performance
* **Debug** - development version with asserts enabled and optimizations disabled

### Windows

To compile for Windows, use Visual Studio solution located in `src/Caissa.sln`. The only tested Visual Studio version is 2022. Using CMake to compile for Windows was not tested.

Simillary as in CMake, there are three configurations defined, but with different names: **Final**, **Release**, **Debug**.

After compilation make sure you copy appropriate neural net file from `data/neuralNets` directory to location where executable file is generated (`build/bin` on Linux or `bin\x64\<Configuration>` on Windows).
